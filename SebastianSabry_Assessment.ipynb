{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da6991d-4b82-4f07-9660-a94d489ab3a7",
   "metadata": {},
   "source": [
    "## Installation Reqs (Linux Ubuntu)\n",
    "0. <code> conda create -n env_pytorch python=3.12 conda activate env_pytorch <code>\n",
    "1. <code> python3 -m pip install playwright\n",
    "playwright install </code> \n",
    "2. <code> pip install datasets <code>\n",
    "3. <code> pip install transformers <code>\n",
    "4. <code> wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin\n",
    "sudo mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
    "wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda-repo-ubuntu2204-12-4-local_12.4.0-550.54.14-1_amd64.deb\n",
    "sudo dpkg -i cuda-repo-ubuntu2204-12-4-local_12.4.0-550.54.14-1_amd64.deb\n",
    "sudo cp /var/cuda-repo-ubuntu2204-12-4-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
    "sudo apt-get update\n",
    "sudo apt-get -y install cuda-toolkit-12-4 <code>\n",
    "5. <code> pip install pytorch <code>\n",
    "5. <code> pip install evaluate <code>\n",
    "\n",
    "\n",
    "I found that initially creating a virtual environment in conda with python, then installing the dependencies produced less confusion with the path to pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd670e-a965-4566-b161-afc830bf89ce",
   "metadata": {},
   "source": [
    "## Webscraping \n",
    "\n",
    "This webscraper employs the use of PlayWright, my implementation heavily relies on the CSS selector pattern I see on Google Developer Inspect mode for the website. That, however, did produce some errors when there were unique edge cases in which the Locator object didn't seem to have methods to deal with css patterns of that form. For instance, the table element, and each sub element for nutrient facts proved very odd to process with the Locator object. Otherwise, for simple patterns found for each food page this web scraper did it's job, there was more information to be extracted. Again, the nutrient facts. For the sake of time, I skipped that information. But with more time the code can be extend to include all information on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccba65b2-8fe7-4ae8-8db9-779559daa472",
   "metadata": {},
   "outputs": [],
   "source": [
    "## WEB SCRAPING CELL: \n",
    "from playwright.async_api import async_playwright\n",
    "import asyncio\n",
    "\n",
    "async def process_locator(locator):\n",
    "    count = await locator.count()\n",
    "    if count > 1: #We have many elements and must resolve each inner text\n",
    "        texts = \"\"\n",
    "        for i in range(count):\n",
    "            element = locator.nth(i)\n",
    "            if await element.is_visible():\n",
    "                inner_text = await element.inner_text()\n",
    "                texts = texts + \",\" + inner_text\n",
    "                return texts\n",
    "    else:\n",
    "        if await locator.is_visible():\n",
    "            return await locator.inner_text()\n",
    "        else:\n",
    "            return \"NA\"\n",
    "    \n",
    "\n",
    "async def main():\n",
    "   async with async_playwright() as pw:\n",
    "       browser = await pw.chromium.launch(\n",
    "           ##We'll employ the use of chromium for this webscraper\n",
    "           ##Using a proxy creates HTTP errors.\n",
    "          headless=False\n",
    "      )\n",
    "\n",
    "       #Beginning page: \n",
    "       page = await browser.new_page()\n",
    "       await page.goto('https://world.openfoodfacts.org/')\n",
    "       await page.wait_for_timeout(5000)\n",
    "       result = []\n",
    "       food_urls = []\n",
    "       food_list = await page.query_selector_all('.list_product_a')\n",
    "       for food in food_list:\n",
    "           food_urls.append(await food.get_attribute('href'))\n",
    "           \n",
    "       for food_url in food_urls:\n",
    "            food_info = {}\n",
    "            await page.goto(food_url)\n",
    "            #Title: \n",
    "            title = page.locator(\".title-1\")\n",
    "            food_info['title'] = await process_locator(title)\n",
    "            #Common Name:\n",
    "            common_name = page.locator(\"#field_generic_name_value\")\n",
    "            food_info['common_name'] = await process_locator(common_name)\n",
    "            #Quantity:\n",
    "            quantity = page.locator(\"#field_quantity_value\")\n",
    "            food_info['quantity'] = await process_locator(quantity)\n",
    "            #Packaging: \n",
    "            packaging = page.locator(\"#field_packaging_value\")\n",
    "            food_info['packaging'] = await process_locator(packaging)\n",
    "            #Brands:\n",
    "            brand = page.locator(\"#field_brands_value\")\n",
    "            food_info['brand'] = await process_locator(brand)\n",
    "            #Categories:\n",
    "            categories = page.locator(\"#field_categories_value\")\n",
    "            food_info['categories'] = await process_locator(categories)\n",
    "            #Certifications:\n",
    "            certifications = page.locator(\"#field_labels_value\")\n",
    "            food_info['certifications'] = await process_locator(certifications)\n",
    "            #Origin:\n",
    "            origin = page.locator(\"#field_origin_value\")\n",
    "            food_info['origin'] = await process_locator(origin)\n",
    "            #origin of ingredients:\n",
    "            origin_of_ingredients = page.locator(\"#field_origins_value\")\n",
    "            food_info['origin_of_ingredients'] = await process_locator(origin_of_ingredients)\n",
    "            #Places of manufacturing:\n",
    "            places_manufactured = page.locator(\"#field_manufacturing_places_value\")\n",
    "            food_info['places_manufactured'] = await process_locator(places_manufactured)\n",
    "            #Stores:\n",
    "            stores = page.locator(\"#field_stores_value\")\n",
    "            food_info['stores'] = await process_locator(stores)\n",
    "            #Countries where Sold:\n",
    "            countries_sold = page.locator(\"#field_countries_value\")\n",
    "            food_info['countries_sold'] = await process_locator(countries_sold)\n",
    "           \n",
    "            #HEALTH SECTION\n",
    "            #Notice, because of the increasing complexity of the DOM elements in this area the CSS selectors don't follow a similarly nice pattern\n",
    "            #Ingredients: \n",
    "            ingredients = page.locator(\"#panel_ingredients_content .panel_text\")\n",
    "            food_info['ingredients'] = await process_locator(ingredients)\n",
    "            #NOVA score:\n",
    "            nova_score = page.locator(\"ul#panel_nova li.accordion-navigation h4\")\n",
    "            food_info['nova_score'] = await process_locator(nova_score)\n",
    "            # #Palm Status:\n",
    "            # palm_status = page.locator(\".accordion-navigation active .content panel_content active .panel_text\")\n",
    "            # food_info['palm_status'] = await process_locator(palm_status)\n",
    "            # #Vegan Status:\n",
    "            # vegan_status = page.locator(\"#panel_ingredients_analysis_en-vegan_content .panel_text\")\n",
    "            # food_info['vegan_status'] = await process_locator(vegan_status)\n",
    "            # #Vegetarian Status:\n",
    "            # vegetarian_status = page.locator(\"#panel_ingredients_analysis_en-vegetarian_content .panel_text\")\n",
    "            # food_info['vegetarian_status'] = await process_locator(vegetarian_status)\n",
    "            #Nutrition grade:\n",
    "            nutrition_grade = page.locator(\".accordion-navigation .grade_a_title\")\n",
    "            food_info['nutrition_grade'] = await process_locator(nutrition_grade)\n",
    "\n",
    "            # #NUTITRION FACTS\n",
    "            # #\n",
    "            # table_rows = await page.query_selector_all(\"#panel_nutrition_facts_table_content\")\n",
    "            # nutrition_facts = {}\n",
    "            # for row in table_rows:\n",
    "            #     columns = await row.query_selector_all('td')\n",
    "            #     name = await process_locator(columns[0])\n",
    "            #     value_per_100g = await process_locator(columns[1])\n",
    "            #     nutrition_facts[name] = {\n",
    "            #         \"100g/100ml\": value_per_100g\n",
    "            #     }\n",
    "                    \n",
    "                    \n",
    "            # food_info['nutrition_table'] = nutrition_facts\n",
    "            result.append(food_info)\n",
    "            \n",
    "\n",
    "\n",
    "       \n",
    "       \n",
    "\n",
    "       \n",
    "           \n",
    "           \n",
    "           \n",
    "       await browser.close()\n",
    "       return result\n",
    "if __name__ == '__main__':\n",
    "   result = await main()\n",
    "\n",
    "#Problems & Changes:\n",
    "#\n",
    "\n",
    "#CITATIONs: \n",
    "#Code cited from OxyLabs: https://github.com/oxylabs/playwright-web-scraping?tab=readme-ov-file\n",
    "#,https://playwright.dev/python/docs/locators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "435918ad-288a-4d30-84c6-e1a8e6d5eced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': \"Huile d'olive vierge extra - Domaine de Bournissac - 500\\xa0ml\",\n",
       " 'common_name': \"Huile d'olive\",\n",
       " 'quantity': '500 ml',\n",
       " 'packaging': 'NA',\n",
       " 'brand': 'Domaine de Bournissac',\n",
       " 'categories': 'Plant-based foods and beverages, Plant-based foods, Fats, Vegetable fats, Olive tree products, Vegetable oils, Olive oils, Extra-virgin olive oils, Virgin olive oils',\n",
       " 'certifications': 'Organic, EU Organic, FR-BIO-10\\n',\n",
       " 'origin': 'NA',\n",
       " 'origin_of_ingredients': 'NA',\n",
       " 'places_manufactured': 'NA',\n",
       " 'stores': 'NA',\n",
       " 'countries_sold': 'France',\n",
       " 'ingredients': 'NA',\n",
       " 'nova_score': 'Processed culinary ingredients',\n",
       " 'nutrition_grade': 'NA'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb22bb-8f09-4063-a5d4-c19d84db4a06",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "Here we process every instance of food_data such that we create a context, a body of text that contains at some point the answer to our question. The format for the context is quite simple, we take some information from the food_data element and put it into a correct sentence. We then define a function to create a pair of questions and answers, for the sake of simplicity I define 4 questions and answers. This could be extended even further, but requires more preprocessing. We finally convert the list of dictionaries to a Dataset object from HuggingFace's datasets library. Finally the dataset is split into training and validation sets, at a 80/20 split, deterministically (for the purpose of debugging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e20777-da2e-44b2-bbf4-3b92bbdcb6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING CELL\n",
    "from datasets import DatasetDict, Dataset, Features\n",
    "##DATA FORMAT:\n",
    "# Context: 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'\n",
    "# Question: 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'\n",
    "# Answer: {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n",
    "\n",
    "#Defining a function to create the context, in the context part of a QA data format\n",
    "def create_context(food_data):\n",
    "    context = (\n",
    "        f\"{food_data['title']} is commonly known as {food_data['common_name']}. \"\n",
    "        f\"The ingredients are {food_data['ingredients']}. \"\n",
    "        f\"The packaging includes {food_data['packaging']}. \"\n",
    "        f\"The brand is {food_data['brand']}. \"\n",
    "        f\"It falls under the categories {food_data['categories']}. \"\n",
    "        f\"It has certifications like {food_data['certifications']}. \"\n",
    "        f\"It originates from {food_data['origin']} and the origin of ingredients is {food_data['origin_of_ingredients']}. \"\n",
    "        f\"It is manufactured in {food_data['places_manufactured']}. \"\n",
    "        f\"It is sold in countries like {food_data['countries_sold']}. \"\n",
    "        f\"The nutrition grade is {food_data['nutrition_grade']}. \"\n",
    "        f\"The NOVA score is {food_data['nova_score']}. \"\n",
    "        f\"It can be found in stores such as {food_data['stores']}. \"\n",
    "    )\n",
    "    return context\n",
    "\n",
    "\n",
    "\n",
    "def create_question_answer(food_data, context):\n",
    "    qa_pairs = []\n",
    "\n",
    "    #Generate question about common name \n",
    "    question = \"What is the common name of \" + food_data['title'] + \"?\"\n",
    "    answer = {'text': [food_data['common_name']], 'answer_start':[context.index(food_data['common_name'])]}\n",
    "    qa_pairs.append({'question':question, 'answer':answer})\n",
    "    #Generate question about ingredients\n",
    "    question = \"What are some ingredients in \" + food_data['title'] + \"?\"\n",
    "    answer = {'text':[food_data['ingredients']], 'answer_start':[context.index(food_data['ingredients'])]}\n",
    "    qa_pairs.append({'question':question, 'answer':answer})\n",
    "    #Generate question \n",
    "    question = \"What is the packaging of \" + food_data['title'] + \"?\"\n",
    "    answer = {'text':[food_data['packaging']], 'answer_start':[context.index(food_data['packaging'])]}\n",
    "    qa_pairs.append({'question':question, 'answer':answer})\n",
    "    #Generate Question\n",
    "    question = \"What is the brand of \" + food_data['title'] + \"?\"\n",
    "    answer = {'text':[food_data['brand']], 'answer_start':[context.index(food_data['brand'])]}\n",
    "    qa_pairs.append({'question':question, 'answer':answer})\n",
    "    #Generate Question\n",
    "    \n",
    "    return qa_pairs\n",
    "\n",
    "def create_qac_dataset(food_data_list):\n",
    "    qac_dataset = []\n",
    "    for food_data in food_data_list:\n",
    "        context = create_context(food_data)\n",
    "        qa_pairs = create_question_answer(food_data, context)\n",
    "        for qa in qa_pairs:\n",
    "            current_dict = {\"context\": context, \"question\": qa['question'], \"answer\": qa['answer']}\n",
    "            qac_dataset.append(current_dict)\n",
    "    return qac_dataset\n",
    "        \n",
    "   #As of the current function, it is a deterministic split, this is done for debugging purposes\n",
    "def split_dataset(dataset, split_ratio=0.8):\n",
    "    split_index = int(len(dataset) * split_ratio)\n",
    "    \n",
    "    training_data = dataset[:split_index]\n",
    "    validation_data = dataset[split_index:]\n",
    "    \n",
    "    return {\"train\": training_data, \"validation\": validation_data}\n",
    "\n",
    "\n",
    "\n",
    "#This is the format found on the Hugging Face tutorial, following this contruction for simplicity\n",
    "def convert_to_dataset_dict(training_set, validation_set):\n",
    "    features = Features({\n",
    "        \"id\": \"string\",\n",
    "        \"title\": \"string\",\n",
    "        \"context\": \"string\",\n",
    "        \"question\": \"string\",\n",
    "        \"answers\": \"string\",\n",
    "    })\n",
    "\n",
    "    # Create Dataset objects\n",
    "    train_dataset = Dataset.from_pandas(training_set)\n",
    "    validation_dataset = Dataset.from_pandas(validation_set)\n",
    "\n",
    "    # Create DatasetDict\n",
    "    dataset_dict = DatasetDict({\n",
    "        \"train\": train_dataset,\n",
    "        \"validation\": validation_dataset\n",
    "    })\n",
    "\n",
    "    return dataset_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad1e100b-ab2b-461d-b9f2-f21ef9fd2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our question, answer, context dictionary\n",
    "qac_result = create_qac_dataset(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6bc2714-08a6-47c4-9cef-fc2d44faccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The documentation on Hugging face suggests that this is the best format\n",
    "idx = 0\n",
    "for qa in qac_result:\n",
    "    qa[\"id\"] = str(idx + 1)  # Adding 1 to start id from 1\n",
    "    qa[\"title\"] = f\"Title {idx + 1}\"  # Assuming title follows a pattern, adjust as needed\n",
    "\n",
    "    # Move id and title to the beginning of the dictionary\n",
    "    qa.update({\"id\": qa[\"id\"], \"title\": qa[\"title\"]})\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52bc885d-91f4-4d19-8666-89dcddae786e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': \"Eau de Source - Cristaline - 1,5\\xa0L is commonly known as Spring water. The ingredients are water. The packaging includes Aluminium-can, HdpeFilm-packet, PpFilm-wrapper, Ldpe-film. The brand is Cristaline. It falls under the categories Beverages, Waters, Spring waters. It has certifications like Triman\\n. It originates from Embouteillée à 24610 Saint-Martin de Gurson France and the origin of ingredients is France, fr:Saint-Martin de Gurson. It is manufactured in Saint-Martin de Gurson, France, 24610. It is sold in countries like Belgium, Côte d'Ivoire, France, Germany, Guadeloupe, Italy, Luxembourg, Mali, Martinique, New Caledonia, Switzerland, United Kingdom. The nutrition grade is Very good nutritional quality. The NOVA score is Unprocessed or minimally processed foods. It can be found in stores such as Carrefour, Leclerc, Auchan, Intermarché, Super U, E.Leclerc. \",\n",
       " 'question': 'What is the common name of Eau de Source - Cristaline - 1,5\\xa0L?',\n",
       " 'answer': {'text': ['Spring water'], 'answer_start': [56]},\n",
       " 'id': '1',\n",
       " 'title': 'Title 1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qac_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992ce3d0-9b83-494d-b858-4ea6409fc532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eau de Source - Cristaline - 1,5 L is commonly...</td>\n",
       "      <td>What is the common name of Eau de Source - Cri...</td>\n",
       "      <td>{'text': ['Spring water'], 'answer_start': [56]}</td>\n",
       "      <td>1</td>\n",
       "      <td>Title 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eau de Source - Cristaline - 1,5 L is commonly...</td>\n",
       "      <td>What are some ingredients in Eau de Source - C...</td>\n",
       "      <td>{'text': ['water'], 'answer_start': [63]}</td>\n",
       "      <td>2</td>\n",
       "      <td>Title 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eau de Source - Cristaline - 1,5 L is commonly...</td>\n",
       "      <td>What is the packaging of Eau de Source - Crist...</td>\n",
       "      <td>{'text': ['Aluminium-can, HdpeFilm-packet, PpF...</td>\n",
       "      <td>3</td>\n",
       "      <td>Title 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eau de Source - Cristaline - 1,5 L is commonly...</td>\n",
       "      <td>What is the brand of Eau de Source - Cristalin...</td>\n",
       "      <td>{'text': ['Cristaline'], 'answer_start': [16]}</td>\n",
       "      <td>4</td>\n",
       "      <td>Title 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whole Wheat Chocolate Biscuits - Lu - 300 g is...</td>\n",
       "      <td>What is the common name of Whole Wheat Chocola...</td>\n",
       "      <td>{'text': ['NA'], 'answer_start': [65]}</td>\n",
       "      <td>5</td>\n",
       "      <td>Title 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Levure de bière - Gerblé - 150 g is commonly k...</td>\n",
       "      <td>What is the brand of Levure de bière - Gerblé ...</td>\n",
       "      <td>{'text': ['Gerblé'], 'answer_start': [18]}</td>\n",
       "      <td>316</td>\n",
       "      <td>Title 316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Granola - LU - 200 g e is commonly known as Bi...</td>\n",
       "      <td>What is the common name of Granola - LU - 200 ...</td>\n",
       "      <td>{'text': ['Biscuits sablés nappés de chocolat ...</td>\n",
       "      <td>317</td>\n",
       "      <td>Title 317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Granola - LU - 200 g e is commonly known as Bi...</td>\n",
       "      <td>What are some ingredients in Granola - LU - 20...</td>\n",
       "      <td>{'text': [',wheat flour 48%, milk chocolate 27...</td>\n",
       "      <td>318</td>\n",
       "      <td>Title 318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Granola - LU - 200 g e is commonly known as Bi...</td>\n",
       "      <td>What is the packaging of Granola - LU - 200 g e?</td>\n",
       "      <td>{'text': ['fr:sachet plastique, fr:étui carton...</td>\n",
       "      <td>319</td>\n",
       "      <td>Title 319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>Granola - LU - 200 g e is commonly known as Bi...</td>\n",
       "      <td>What is the brand of Granola - LU - 200 g e?</td>\n",
       "      <td>{'text': ['LU'], 'answer_start': [10]}</td>\n",
       "      <td>320</td>\n",
       "      <td>Title 320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    Eau de Source - Cristaline - 1,5 L is commonly...   \n",
       "1    Eau de Source - Cristaline - 1,5 L is commonly...   \n",
       "2    Eau de Source - Cristaline - 1,5 L is commonly...   \n",
       "3    Eau de Source - Cristaline - 1,5 L is commonly...   \n",
       "4    Whole Wheat Chocolate Biscuits - Lu - 300 g is...   \n",
       "..                                                 ...   \n",
       "315  Levure de bière - Gerblé - 150 g is commonly k...   \n",
       "316  Granola - LU - 200 g e is commonly known as Bi...   \n",
       "317  Granola - LU - 200 g e is commonly known as Bi...   \n",
       "318  Granola - LU - 200 g e is commonly known as Bi...   \n",
       "319  Granola - LU - 200 g e is commonly known as Bi...   \n",
       "\n",
       "                                              question  \\\n",
       "0    What is the common name of Eau de Source - Cri...   \n",
       "1    What are some ingredients in Eau de Source - C...   \n",
       "2    What is the packaging of Eau de Source - Crist...   \n",
       "3    What is the brand of Eau de Source - Cristalin...   \n",
       "4    What is the common name of Whole Wheat Chocola...   \n",
       "..                                                 ...   \n",
       "315  What is the brand of Levure de bière - Gerblé ...   \n",
       "316  What is the common name of Granola - LU - 200 ...   \n",
       "317  What are some ingredients in Granola - LU - 20...   \n",
       "318   What is the packaging of Granola - LU - 200 g e?   \n",
       "319       What is the brand of Granola - LU - 200 g e?   \n",
       "\n",
       "                                                answer   id      title  \n",
       "0     {'text': ['Spring water'], 'answer_start': [56]}    1    Title 1  \n",
       "1            {'text': ['water'], 'answer_start': [63]}    2    Title 2  \n",
       "2    {'text': ['Aluminium-can, HdpeFilm-packet, PpF...    3    Title 3  \n",
       "3       {'text': ['Cristaline'], 'answer_start': [16]}    4    Title 4  \n",
       "4               {'text': ['NA'], 'answer_start': [65]}    5    Title 5  \n",
       "..                                                 ...  ...        ...  \n",
       "315         {'text': ['Gerblé'], 'answer_start': [18]}  316  Title 316  \n",
       "316  {'text': ['Biscuits sablés nappés de chocolat ...  317  Title 317  \n",
       "317  {'text': [',wheat flour 48%, milk chocolate 27...  318  Title 318  \n",
       "318  {'text': ['fr:sachet plastique, fr:étui carton...  319  Title 319  \n",
       "319             {'text': ['LU'], 'answer_start': [10]}  320  Title 320  \n",
       "\n",
       "[320 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#Let us split the dataset into training, and validation\n",
    "qac_dataset = split_dataset(qac_result, split_ratio=0.8)\n",
    "training_list = qac_dataset[\"train\"]\n",
    "validation_list = qac_dataset[\"validation\"]\n",
    "#Convert to pandas Dataframe object so that we can use a default Dataset.from_pandas()\n",
    "df_training = pd.DataFrame(training_list)\n",
    "df_validation = pd.DataFrame(validation_list)\n",
    "df_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c23c1a-f658-459c-b31b-093f4a8781de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = convert_to_dataset_dict(df_training, df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75506087-0a06-45b0-974e-e4e9658e7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the tutorial: https://huggingface.co/learn/nlp-course/en/chapter7/7 we'll use the bert-base-cased model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "#Based on the tutorial we want to insert tokens create a sentence of this form: \n",
    "#[CLS] question [SEP] context [SEP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903764a-ca85-406c-85a4-aabbbe9efbb2",
   "metadata": {},
   "source": [
    "## Begin Testing preproccess\n",
    "\n",
    "Notice: Much of this code is to ensure that my scraped data follows the same format as given on the Hugging Face documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37111e3f-2b11-4569-8629-e116f58cded1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] What is the common name of Eau de Source - Cristaline - 1, 5 L? [SEP] Eau de Source - Cristaline - 1, 5 L is commonly known as Spring water. The ingredients are water. The packaging includes Aluminium - can, HdpeFilm - packet, PpFilm - wrapper, Ldpe - film. The brand is Cristaline. It falls under the categories Beverages, [SEP]\n",
      "[CLS] What is the common name of Eau de Source - Cristaline - 1, 5 L? [SEP] The packaging includes Aluminium - can, HdpeFilm - packet, PpFilm - wrapper, Ldpe - film. The brand is Cristaline. It falls under the categories Beverages, Waters, Spring waters. It has certifications like Triman. It originates from Embouteillée à 24610 Saint - [SEP]\n",
      "[CLS] What is the common name of Eau de Source - Cristaline - 1, 5 L? [SEP], Ldpe - film. The brand is Cristaline. It falls under the categories Beverages, Waters, Spring waters. It has certifications like Triman. It originates from Embouteillée à 24610 Saint - Martin de Gurson France and the origin of ingredients is France, fr : Saint - Martin de Gurson. It [SEP]\n",
      "[CLS] What is the common name of Eau de Source - Cristaline - 1, 5 L? [SEP] Spring waters. It has certifications like Triman. It originates from Embouteillée à 24610 Saint - Martin de Gurson France and the origin of ingredients is France, fr : Saint - Martin de Gurson. It is manufactured in Saint - Martin de Gurson, France, 24610. It is sold in countries like Belgium, Côte d [SEP]\n",
      "[CLS] What is the common name of Eau de Source - Cristaline - 1, 5 L? [SEP] Gurson France and the origin of ingredients is France, fr : Saint - Martin de Gurson. It is manufactured in Saint - Martin de Gurson, France, 24610. It is sold in countries like Belgium, Côte d'Ivoire, France, Germany, Guadeloupe, Italy, Luxembourg, Mali, Martinique, New Caledonia, [SEP]\n",
      "[CLS] What is the common name of Eau de Source - Cristaline - 1, 5 L? [SEP] in Saint - Martin de Gurson, France, 24610. It is sold in countries like Belgium, Côte d'Ivoire, France, Germany, Guadeloupe, Italy, Luxembourg, Mali, Martinique, New Caledonia, Switzerland, United Kingdom. The nutrition grade is Very good nutritional quality. The NOVA score is Unprocessed or [SEP]\n",
      "[CLS] What is the common name of Eau de Source - Cristaline - 1, 5 L? [SEP]voire, France, Germany, Guadeloupe, Italy, Luxembourg, Mali, Martinique, New Caledonia, Switzerland, United Kingdom. The nutrition grade is Very good nutritional quality. The NOVA score is Unprocessed or minimally processed foods. It can be found in stores such as Carrefour, Leclerc, Auchan, Intermar [SEP]\n",
      "[CLS] What is the common name of Eau de Source - Cristaline - 1, 5 L? [SEP] United Kingdom. The nutrition grade is Very good nutritional quality. The NOVA score is Unprocessed or minimally processed foods. It can be found in stores such as Carrefour, Leclerc, Auchan, Intermarché, Super U, E. Leclerc. [SEP]\n"
     ]
    }
   ],
   "source": [
    "#Test tokenizer format\n",
    "#See the format of splitting the context\n",
    "context = dataset[\"train\"][0]['context']\n",
    "question = dataset[\"train\"][0]['question']\n",
    "\n",
    "inputs = tokenizer(question, \n",
    "                   context, \n",
    "                   max_length = 100, \n",
    "                   truncation=\"only_second\", \n",
    "                   stride = 50, \n",
    "                   return_overflowing_tokens=True,)\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "    print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd9f978-0ff9-45a9-8a70-a93e884f9006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'overflow_to_sample_mapping'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18f4b903-47ed-46be-a9f9-6449b50419cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4 examples gave 45 features.\n",
      "Here is where each comes from: [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3].\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    dataset[\"train\"][2:6][\"question\"],\n",
    "    dataset[\"train\"][2:6][\"context\"],\n",
    "    max_length=100,\n",
    "    truncation=\"only_second\",\n",
    "    stride=50,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    ")\n",
    "\n",
    "print(f\"The 4 examples gave {len(inputs['input_ids'])} features.\")\n",
    "print(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c51aaf1-33ae-4139-8e4b-087c3ba8ce5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([51,\n",
       "  24,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  27,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  39,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [79,\n",
       "  52,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  30,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  40,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = dataset[\"train\"][2:6][\"answer\"]\n",
    "start_positions = []\n",
    "end_positions = []\n",
    "\n",
    "for i, offset in enumerate(inputs[\"offset_mapping\"]):\n",
    "    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n",
    "    answer = answers[sample_idx]\n",
    "    start_char = answer[\"answer_start\"][0]\n",
    "    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "    sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "    # Find the start and end of the context\n",
    "    idx = 0\n",
    "    while sequence_ids[idx] != 1:\n",
    "        idx += 1\n",
    "    context_start = idx\n",
    "    while sequence_ids[idx] == 1:\n",
    "        idx += 1\n",
    "    context_end = idx - 1\n",
    "\n",
    "    # If the answer is not fully inside the context, label is (0, 0)\n",
    "    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "        start_positions.append(0)\n",
    "        end_positions.append(0)\n",
    "    else:\n",
    "        # Otherwise it's the start and end token positions\n",
    "        idx = context_start\n",
    "        while idx <= context_end and offset[idx][0] <= start_char:\n",
    "            idx += 1\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "        idx = context_end\n",
    "        while idx >= context_start and offset[idx][1] >= end_char:\n",
    "            idx -= 1\n",
    "        end_positions.append(idx + 1)\n",
    "\n",
    "start_positions, end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "072ca8e8-2ba9-4805-b519-b540d96a2ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical answer: Aluminium-can, HdpeFilm-packet, PpFilm-wrapper, Ldpe-film, labels give: Aluminium - can, HdpeFilm - packet, PpFilm - wrapper, Ldpe - film\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n",
    "answer = answers[sample_idx][\"text\"][0]\n",
    "\n",
    "start = start_positions[idx]\n",
    "end = end_positions[idx]\n",
    "labeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n",
    "\n",
    "print(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77337c84-81fb-4837-951f-7fceb826ab23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretical answer: Aluminium-can, HdpeFilm-packet, PpFilm-wrapper, Ldpe-film, decoded example: [CLS] What is the packaging of Eau de Source - Cristaline - 1, 5 L? [SEP] and the origin of ingredients is France, fr : Saint - Martin de Gurson. It is manufactured in Saint - Martin de Gurson, France, 24610. It is sold in countries like Belgium, Côte d'Ivoire, France, Germany, Guadeloupe, Italy, Luxembourg, Mali, Martinique, New Caledonia, Switzerland, United Kingdom. [SEP]\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n",
    "answer = answers[sample_idx][\"text\"][0]\n",
    "\n",
    "decoded_example = tokenizer.decode(inputs[\"input_ids\"][idx])\n",
    "print(f\"Theoretical answer: {answer}, decoded example: {decoded_example}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77282c9f-8eb5-4f32-a985-849de0aae33c",
   "metadata": {},
   "source": [
    "## End Testing Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c57b89-fc9e-49a3-b3b4-bb282af031f1",
   "metadata": {},
   "source": [
    "## Further Preprocessing (To format the same as Hugging Face documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f3a0e57-d034-407f-84e3-db7b2dea7bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function cited from: https://huggingface.co/learn/nlp-course/en/chapter7/7\n",
    "#Processing the training data\n",
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answer\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7a2dc0a-4db8-4b0f-8f75-60c995dbad41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b206397b61484a0b92c85b3e1174ccbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(320, 392)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"].map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    ")\n",
    "len(dataset[\"train\"]), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdfaa00c-e53d-4ee5-92cd-4ac3788764a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function cited directly from:https://huggingface.co/learn/nlp-course/en/chapter7/7\n",
    "#Processing the validation Data\n",
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "\n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e114173-cefd-40ac-9542-45c3ca9ca4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7eb554bf254d328da57692e323a7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(80, 116)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = dataset[\"validation\"].map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"validation\"].column_names,\n",
    ")\n",
    "len(dataset[\"validation\"]), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b1328-e664-4aa1-b7c6-cc7c699cd9ee",
   "metadata": {},
   "source": [
    "## Training & Fine-Tuning the Model\n",
    "\n",
    "We use the bert-base-cased from HuggingFace, a pretrained model on English language. It is intended to be fined tuned on tasks like QA. \n",
    "\n",
    "Notice: The majority of this code is referenced from: https://huggingface.co/learn/nlp-course/en/chapter7/7 tutorial. On exactly how to evaluate a QA system "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4255da3d-bc39-4d58-8adb-c9eadf598baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16414374372c45dfa2abc3ddcb9a6a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_eval_set = dataset[\"validation\"].select(range(40))\n",
    "trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "eval_set = small_eval_set.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"validation\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5714c608-5243-4829-9c6c-01bd516ee37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8936cccd-f55b-4b13-b218-1ed9cfefd2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('/home/sebastiancsabry/miniconda3/lib/python3.12/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54407fcb-0208-4db0-9895-e42481b96e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"torch\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n",
    "trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = trained_model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74949b9c-739b-44cb-b6f7-20c27e1e67bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cbc0e92-923c-4f02-97b1-b45203232af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "example_to_features = collections.defaultdict(list)\n",
    "for idx, feature in enumerate(eval_set):\n",
    "    example_to_features[feature[\"example_id\"]].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47f72aad-3b3b-415f-9d1e-c0f5a93394c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "predicted_answers = []\n",
    "\n",
    "for example in small_eval_set:\n",
    "    example_id = example[\"id\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = []\n",
    "\n",
    "    for feature_index in example_to_features[example_id]:\n",
    "        start_logit = start_logits[feature_index]\n",
    "        end_logit = end_logits[feature_index]\n",
    "        offsets = eval_set[\"offset_mapping\"][feature_index]\n",
    "\n",
    "        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Skip answers that are not fully in the context\n",
    "                if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                    continue\n",
    "                # Skip answers with a length that is either < 0 or > max_answer_length.\n",
    "                if (\n",
    "                    end_index < start_index\n",
    "                    or end_index - start_index + 1 > max_answer_length\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                answers.append(\n",
    "                    {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae2fcbe6-0c67-4002-95f8-0a770731fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a122accd-70f1-4243-877f-b1bc011fdac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_answers = [\n",
    "    {\"id\": ex[\"id\"], \"answers\": ex[\"answer\"]} for ex in small_eval_set\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6486332-8dfd-4e32-84b3-d942fc5620b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '328', 'prediction_text': 'Sucre'}\n",
      "{'id': '328', 'answers': {'answer_start': [0], 'text': ['Sunny Via']}}\n"
     ]
    }
   ],
   "source": [
    "print(predicted_answers[7])\n",
    "print(theoretical_answers[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e04a5-631d-4246-a92d-262ed1e5b867",
   "metadata": {},
   "source": [
    "Notice here, with just a test on the predicted and theoretical answers we have a relatively low score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77df3d1f-d2bd-4acf-a576-3f83ebede613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 40.0, 'f1': 51.537402104080776}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8897c-08fc-47f4-a98f-4272640bfa2b",
   "metadata": {},
   "source": [
    "We will assess the performance of the model with the use of this function compute_metrics; using beginning and end logits of each answer, then use the metric.compute() function to asses the score = (start_logit + end_logit). Metric.compute() uses the \"Squad\" metric, which is used for evaluating Question Answering models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf6f00fc-d757-40ad-8823-aec9657899e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answer\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers) #Squad evaluation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66d3cfd6-0f33-4a1b-bbb8-fd656099471c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d4021bdf0542d6a50dc969b0ee88b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 40.0, 'f1': 51.537402104080776}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(start_logits, end_logits, eval_set, small_eval_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca6241-4989-4829-b2f1-6d48d91b92f6",
   "metadata": {},
   "source": [
    "Again, above we see that without fine-tuning we have a relatively low score of 40.0! We'll see if some fine-tuning mediates this score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95331365-5f54-4a62-916a-9e53ed28a3f0",
   "metadata": {},
   "source": [
    "## Fine-Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91719887-26a4-4ad0-a452-3c087ed348d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8099b78e-d3ba-4856-a362-a28e55a01b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5f398ca60e4e268217da06c160c7a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Logging in here as part of the tutorial\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4438823b-5c19-4002-a9e0-4bfaa1f431cf",
   "metadata": {},
   "source": [
    "Here I use the parameters from the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c2baf41-2d45-4573-a5c8-9124dc17c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-squad\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a34ebac0-77b9-4c90-a6d6-754cfc59b803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastiancsabry/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='147' max='147' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [147/147 00:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[1;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      4\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      5\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m      9\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/transformers/trainer.py:1771\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1769\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1770\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1772\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1773\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1774\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1775\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1776\u001b[0m     )\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1778\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/transformers/trainer.py:2278\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_train_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;66;03m# Wait for the checkpoint to be uploaded.\u001b[39;00m\n\u001b[0;32m-> 2278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_finish_current_push()\n\u001b[1;32m   2280\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m   2282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/transformers/trainer.py:3970\u001b[0m, in \u001b[0;36mTrainer._finish_current_push\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_in_progress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_in_progress\u001b[38;5;241m.\u001b[39mis_done():\n\u001b[1;32m   3969\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting for the current checkpoint push to be finished, this might take a couple of minutes.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3970\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_in_progress\u001b[38;5;241m.\u001b[39mwait_until_done()\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/transformers/utils/hub.py:1242\u001b[0m, in \u001b[0;36mPushInProgress.wait_until_done\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_until_done\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m-> 1242\u001b[0m     futures\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs)\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/concurrent/futures/_base.py:305\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m DoneAndNotDoneFutures(done, not_done)\n\u001b[1;32m    303\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 305\u001b[0m waiter\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_condition:\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/env_pytorch/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31e7b062-614c-4a06-a678-6398598eb888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd71f8fe5c19447cb20a545799ec5ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'exact_match': 65.0, 'f1': 66.8044820331491}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, _, _ = trainer.predict(validation_dataset)\n",
    "start_logits, end_logits = predictions\n",
    "compute_metrics(start_logits, end_logits, validation_dataset, dataset[\"validation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bdd48-0402-4047-9cc1-66e7aee9decb",
   "metadata": {},
   "source": [
    "Above, we see that our exact match score is much higher than 40.0, with the trainer. Next we'll use an optimizer to push this score further."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72134658-c708-464b-8e4c-7a8d5f95c4dc",
   "metadata": {},
   "source": [
    "We do some hyperparameter tuning, beyond the default arguments\n",
    "\n",
    "This code very closely follows: https://huggingface.co/learn/nlp-course/en/chapter7/7 Section on Custom Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96382c81-0a7b-484c-8a3d-e3eece3336c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "validation_set = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "validation_set.set_format(\"torch\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn=default_data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    validation_set, collate_fn=default_data_collator, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2511a4a-451d-4bca-8559-a2bd6d749224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#We reset the model to the pre-training version\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5fb46-32b3-4477-b6ef-973c31036142",
   "metadata": {},
   "source": [
    "We employ the use of AdamW to optimize our models parameters. AdamW is an optimizer with weight decay, using gradient accumulation. Here adamW gradually optimizes the model by minimizing the loss-function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67fb3bd0-73a9-4899-ba98-3289f16b8ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f5b146e-95f9-4dd9-9132-0ae5c8c95211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator('fp16')\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74fb245d-0f47-45e9-ae17-ff779637d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 5\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ab14b13-c7ab-45d3-91d2-c41113265998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TheUnknot/bert-finetuned-squad'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This code block is used to simply save the fine-tuned model for later use\n",
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"bert-finetuned-squad\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "675a3f4d-baf8-4ab6-9d83-8f87dbb3935f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastiancsabry/miniconda3/envs/env_pytorch/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "/home/sebastiancsabry/Documents/Projects/RAGvsFine/bert-finetuned-squad-accelerate is already a clone of https://huggingface.co/TheUnknot/bert-finetuned-squad. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "#This code block is used to simply save the fine-tuned model for later use\n",
    "output_dir = \"bert-finetuned-squad-accelerate\"\n",
    "repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "083279ef-d6dc-487f-af92-774d0eb330e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5edd911efce4c23b5305b8144a60f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/245 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ca2c9b7a024394beb12485af3ca8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f630b117a543b2ace2de3663b537de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'exact_match': 33.75, 'f1': 37.28439968076291}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (8) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997f6de9f3da461692a137c450b63436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aa8151ae7c42cea1759ec6b60501d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: {'exact_match': 71.25, 'f1': 74.64352804884267}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (9) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c51bee203664c5192c0a6cd6ba3b653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02dd2016a8f04b68b2b3efed29daa947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: {'exact_match': 73.75, 'f1': 74.04166666666666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (10) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9050091083b840d481f1ea55d82dabb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03b6f15e0f649c49da78e178826ff25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: {'exact_match': 72.5, 'f1': 72.91666666666667}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (11) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0697d47c194b1a910b2b6bb00f80d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bc7639775e48918224c61992c8f9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: {'exact_match': 71.25, 'f1': 72.01522435897436}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (12) will be pushed upstream.\n",
      "'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/9e/ba/9eba72b93301803727f5e155402ce06b51910d672d7f30d56eb4b9c74431e8a7/df538ddb3f76d66a4378f4bf4af1eda7d91f9e58aa3dffa04e31c45b5f656f1e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQFN2FTF47%2F20240328%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240328T021953Z&X-Amz-Expires=86400&X-Amz-Signature=3b0d13fa1820f534b9742467d785966610bd400e5bdbc66be32aea39d051e5ac&X-Amz-SignedHeaders=host&partNumber=26&uploadId=Crm6B9kfJYqjrRTLD5XyO57MXO7vezAkq87JlUoTNsiYr2KwVx_djsulUeboAfQ6NRwdXRkU7vnYHHVXW_RcYZv3KtUCe1mdB3x4AEXF35tBTMp2XiJasGQx1zPfAydJ&x-id=UploadPart (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:2406)')))\"), '(Request ID: 3228edee-a000-44cb-8b2a-bcd7d5c8017a)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/9e/ba/9eba72b93301803727f5e155402ce06b51910d672d7f30d56eb4b9c74431e8a7/df538ddb3f76d66a4378f4bf4af1eda7d91f9e58aa3dffa04e31c45b5f656f1e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQFN2FTF47%2F20240328%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240328T021953Z&X-Amz-Expires=86400&X-Amz-Signature=3b0d13fa1820f534b9742467d785966610bd400e5bdbc66be32aea39d051e5ac&X-Amz-SignedHeaders=host&partNumber=26&uploadId=Crm6B9kfJYqjrRTLD5XyO57MXO7vezAkq87JlUoTNsiYr2KwVx_djsulUeboAfQ6NRwdXRkU7vnYHHVXW_RcYZv3KtUCe1mdB3x4AEXF35tBTMp2XiJasGQx1zPfAydJ&x-id=UploadPart\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    accelerator.print(\"Evaluation!\")\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        start_logits.append(accelerator.gather(outputs.start_logits).cpu().numpy())\n",
    "        end_logits.append(accelerator.gather(outputs.end_logits).cpu().numpy())\n",
    "\n",
    "    start_logits = np.concatenate(start_logits)\n",
    "    end_logits = np.concatenate(end_logits)\n",
    "    start_logits = start_logits[: len(validation_dataset)]\n",
    "    end_logits = end_logits[: len(validation_dataset)]\n",
    "\n",
    "    metrics = compute_metrics(\n",
    "        start_logits, end_logits, validation_dataset, dataset[\"validation\"]\n",
    "    )\n",
    "    print(f\"epoch {epoch}:\", metrics)\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c406987-54db-4ef8-b3dd-af900a61bdd3",
   "metadata": {},
   "source": [
    "Look at that, our average squad score is 64.5 is significantly better than the initial test (without fine-tuning) of 40. (I'm unsure as to why our initial epoch provides a 33.75 score, but as we increase the number of epochs the score tends to converge to around a score of 70). Note: There is a possibility of improvement through changing the parameters of our optimizer AdamW. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
